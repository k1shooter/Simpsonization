import torch
from diffusers import StableDiffusionInpaintPipeline
from PIL import Image
import numpy as np
from peft import LoraConfig, get_peft_model, set_peft_model_state_dict

# ëª¨ë¸ ë° ë””ë°”ì´ìŠ¤ ì„¤ì •
MODEL_ID = "stabilityai/stable-diffusion-2-inpaint" # SD2 Inpaint ëª¨ë¸ ì‚¬ìš© ê°€ì •
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# 1. SD-Inpaint Pipeline ë¡œë“œ (U-Net ë° VAE ì‚¬ìš©)
pipe = StableDiffusionInpaintPipeline.from_pretrained(MODEL_ID, torch_dtype=torch.float16)
pipe.to(DEVICE)
# U-Netì„ LoRA fine-tuningì„ ìœ„í•´ ì¤€ë¹„
unet = pipe.unet

## LoRA ì„¤ì •
# ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ rank=16 ì„¤ì • [cite: 251]
lora_config = LoraConfig(
    r=16, 
    lora_alpha=16,
    target_modules=["to_k", "to_v"], # Key(K)ì™€ Value(V) í–‰ë ¬ì— ì ìš© [cite: 193, 199]
    lora_dropout=0.0,
    bias="none",
)

# 2. LoRA ëª¨ë¸ ìƒì„± ë° ê¸°ì¡´ U-Net ìœ„ì— ì ìš©
# get_peft_model í•¨ìˆ˜ê°€ ìë™ìœ¼ë¡œ ê¸°ì¡´ U-Net ê°€ì¤‘ì¹˜ë¥¼ ë™ê²°í•˜ê³  
# target_modulesì— LoRA ë ˆì´ì–´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
lora_unet = get_peft_model(unet, lora_config)
lora_unet.train()
# print(lora_unet.print_trainable_parameters()) 
# ì¶œë ¥í•´ë³´ë©´ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°(LoRA)ëŠ” ì „ì²´ íŒŒë¼ë¯¸í„°ì˜ ê·¹íˆ ì¼ë¶€ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

def masked_denoising_loss(noise_pred, noise_target, mask):
    """ë…¼ë¬¸ Equation (4) êµ¬í˜„: ë§ˆìŠ¤í‚¹ëœ ì˜ì—­ì—ì„œë§Œ ì†ì‹¤ ê³„ì‚°"""
    # maskëŠ” 0(ë³´ì¡´ ì˜ì—­) ë˜ëŠ” 1(ì¸í˜ì¸íŒ… ì˜ì—­) ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.
    # noise_predì™€ noise_targetì— ë§ˆìŠ¤í¬ë¥¼ ê³±í•˜ì—¬ ìœ íš¨ ì˜ì—­(ë§ˆìŠ¤í¬=1)ì˜ ë…¸ì´ì¦ˆë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    
    # í…ì„œ í¬ê¸° ë§ì¶”ê¸° (U-Net ì…ë ¥ì€ ì ì¬ ê³µê°„ í¬ê¸°ì´ë¯€ë¡œ ë§ˆìŠ¤í¬ë„ ë¦¬ì‚¬ì´ì§•ë˜ì–´ì•¼ í•¨)
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„° ë¡œë”ì—ì„œ ì ì¬ ê³µê°„ í¬ê¸°ì— ë§ì¶° ë§ˆìŠ¤í¬ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    
    # ì—¬ê¸°ì„œ maskëŠ” (B, 1, H, W) ë˜ëŠ” (B, 4, H, W) í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
    # U-Netì€ Latent Spaceì—ì„œ ì‘ë™í•˜ë¯€ë¡œ, ë§ˆìŠ¤í¬ë„ Latent Space í¬ê¸°ë¡œ ë³€í™˜ë˜ì—ˆë‹¤ê³  ê°€ì •
    
    masked_pred = noise_pred * mask
    masked_target = noise_target * mask
    
    # MSE Loss ê³„ì‚°
    loss = torch.mean((masked_pred - masked_target) ** 2)
    return loss

# 3. GPT-4Vë¡œ ë¯¸ë¦¬ ìƒì„±ëœ ê³ ì • í”„ë¡¬í”„íŠ¸ (ë…¼ë¬¸ Fig. 2 ì°¸ì¡°)
# 'a photo of an adorable yellow cartoon figure with big eyes and blue clothes, simpsons style'
EXEMPLAR_PROMPT = "A photo of an adorable yellow cartoon figure with big eyes and blue clothes, simpsons style."

# í”„ë¡¬í”„íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (Text EncoderëŠ” Frozen)
text_embeddings = pipe.text_encoder(
    pipe.tokenizer(EXEMPLAR_PROMPT, padding="max_length", truncation=True, 
                   max_length=pipe.tokenizer.model_max_length, return_tensors="pt").input_ids.to(DEVICE)
)[0]

# í•™ìŠµ ë£¨í”„ (ê°„ì†Œí™”ëœ ì˜ˆì‹œ)
optimizer = torch.optim.AdamW(lora_unet.parameters(), lr=5e-5) # ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ í•™ìŠµë¥  [cite: 254]
num_train_epochs = 300 # ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ë°˜ë³µ íšŸìˆ˜ [cite: 254]

# ... (ë°ì´í„° ë¡œë” ì„¤ì •: exemplar augmented image, mask, latent mask, noise) ...

# for epoch in range(num_train_epochs):
    # for batch in dataloader:
        # z_t, noise_target, latent_mask, text_embeddings = batch
        
        # noise_pred = lora_unet(z_t, t, encoder_hidden_states=text_embeddings, 
        #                      down_block_additional_residuals=z_m, 
        #                      mid_block_additional_residual=m).sample
        
        # loss = masked_denoising_loss(noise_pred, noise_target, latent_mask)
        
        # optimizer.zero_grad()
        # loss.backward()
        # optimizer.step()

def prior_noise_initialization(background_img, exemplar_img, mask, vae, scheduler):
    """
    ë…¼ë¬¸ Fig. 3 ë° Equation (5) êµ¬í˜„: í•©ì„± ì´ë¯¸ì§€ì—ì„œ Prior Noise ìƒì„±
    
    Args:
        background_img (PIL.Image): ë°°ê²½ ì´ë¯¸ì§€.
        exemplar_img (PIL.Image): ì‹¬ìŠ¨ ì–¼êµ´ Exemplar ì´ë¯¸ì§€.
        mask (PIL.Image): ì¸í˜ì¸íŒ… ë§ˆìŠ¤í¬ (0-255).
    """
    # 1. Composited Image (í•©ì„± ì´ë¯¸ì§€) ìƒì„± (ë…¼ë¬¸ Fig. 3 ì°¸ì¡°)
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë§ˆìŠ¤í¬ ì˜ì—­ì— Exemplarë¥¼ ë¶™ì—¬ì•¼ í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ê°„ì†Œí™”ëœ ì˜ˆì‹œë¡œ, ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ê³ ë ¤í•˜ì—¬ í•©ì„±í•©ë‹ˆë‹¤.
    # (Bounding Boxë¥¼ ì°¾ê³  ë¦¬ì‚¬ì´ì¦ˆ/ë³µì‚¬í•˜ëŠ” ë¡œì§ì€ ìƒëµ)
    
    # ğŸš¨ PNIë¥¼ ìœ„í•´ì„œëŠ” Exemplarê°€ ë§ˆìŠ¤í¬ ì˜ì—­ì— ë³µì‚¬ëœ ì´ë¯¸ì§€(composited_image)ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    # ì´ ê³¼ì •ì€ NumPy/PIL/OpenCVë¡œ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
    
    # Example: ì„ì˜ì˜ Composited Image (ì ì¬ ê³µê°„) z_hat_0ë¥¼ ìƒì„±í–ˆë‹¤ê³  ê°€ì •
    # ë°°ê²½ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ VAE ì¸ì½”ë”©ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.
    
    # VAEë¥¼ ì‚¬ìš©í•˜ì—¬ Composited Imageë¥¼ ì ì¬ ê³µê°„(z_0)ìœ¼ë¡œ ë³€í™˜
    # z_hat_0 = vae.encode(composited_image).latent_dist.sample() * 0.18215 
    
    # 2. DDPM Forward (ë…¸ì´ì¦ˆ ì¶”ê°€) ìˆ˜í–‰ (Equation 5)
    # TëŠ” ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… (ì˜ˆ: 1000)
    T = scheduler.config.num_train_timesteps
    
    # DDPM Forwardì— í•„ìš”í•œ ê°’ (alpha_T, sigma_T) íšë“
    # TëŠ” ì¸ë±ìŠ¤ê°€ ì•„ë‹Œ ìŠ¤í… ë²ˆí˜¸ë¡œ, ìŠ¤ì¼€ì¤„ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ì‹œ ì²˜ë¦¬ í•„ìš”
    
    # ì˜ˆì‹œ: ëœë¤ ë…¸ì´ì¦ˆ ìƒì„± (epsilon)
    epsilon = torch.randn_like(z_hat_0).to(DEVICE)
    
    # Prior Noise z_T ê³„ì‚° (ê°„ì†Œí™”ëœ ìˆ˜ì‹ êµ¬ì¡°)
    # alpha_T = scheduler.alphas_cumprod[T-1].sqrt()
    # sigma_T = (1 - scheduler.alphas_cumprod[T-1]).sqrt()
    
    # z_T = alpha_T * z_hat_0 + sigma_T * epsilon # Equation (5)
    
    # (ì‹¤ì œ diffusers íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” scheduler.add_noise() í•¨ìˆ˜ë¥¼ ì‚¬ìš©)
    
    # 3. U-Netì— ë¡œë“œí•  Prior Noiseë¥¼ ë°˜í™˜
    # return z_T 
    pass # ì‹¤ì œ pipe.generate() í˜¸ì¶œì„ ìœ„í•´ ë¡œì§ì„ ìƒëµí•˜ê³  pipe í˜¸ì¶œì„ ë³´ì—¬ì¤Œ

# 5. ì¶”ë¡  ë‹¨ê³„
def run_inference(background_img, mask_img, prompt, lora_weights_path):
    # í•™ìŠµëœ LoRA ê°€ì¤‘ì¹˜ ë¡œë“œ
    lora_unet.load_state_dict(torch.load(lora_weights_path))
    lora_unet.eval()
    
    # ğŸš¨ Prior Noise Initializationì„ ìœ„í•œ ìˆ˜ì • (pipe.run_inference í•¨ìˆ˜ ë‚´ì—ì„œ ìˆ˜í–‰)
    # Stable Diffusion Inpaint Pipelineì€ ì¼ë°˜ì ìœ¼ë¡œ random noiseë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
    # PNIë¥¼ ì ìš©í•˜ë ¤ë©´ íŒŒì´í”„ë¼ì¸ì˜ ë‚´ë¶€ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜, 
    # 'latents' ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ PNIë¡œ ìƒì„±ëœ z_Të¥¼ ì§ì ‘ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.
    
    # pipe.scheduler.set_timesteps(num_inference_steps=50) # ë…¼ë¬¸ ì„¤ì • [cite: 255]
    
    # PNIë¥¼ í†µí•´ ìƒì„±ëœ z_Të¥¼ latents ì¸ìˆ˜ë¡œ ì „ë‹¬í•œë‹¤ê³  ê°€ì •
    # initial_noise = prior_noise_initialization(...) 
    
    output = pipe(
        prompt=prompt,
        image=background_img,
        mask_image=mask_img,
        # latents=initial_noise, # PNI ì ìš©
        guidance_scale=8.0, # ë…¼ë¬¸ ì„¤ì • [cite: 255]
        num_inference_steps=50, # ë…¼ë¬¸ ì„¤ì • [cite: 255]
        # negative_prompt=NEGATIVE_PROMPT, # ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰ëœ Neg. Prompt [cite: 208]
    ).images[0]
    
    return output

# --- ì‹¤í–‰ ì˜ˆì‹œ ---
# background = Image.open("background.jpg")
# mask = Image.open("mask.jpg")
# lora_weights = "simpson_lora_weights.pt"
# result_image = run_inference(background, mask, EXEMPLAR_PROMPT, lora_weights)
# result_image.save("inpainted_simpson.png")